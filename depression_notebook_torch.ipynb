{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df1199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\Project\\Depression_detection_project\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd299604",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2845a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/reshuffle_train.tsv\", delimiter='\\t')\n",
    "dev_df = pd.read_csv(\"./data/reshuffle_dev.tsv\", delimiter='\\t')\n",
    "test_df = pd.read_csv(\"./data/reshuffle_test.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1245106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292</td>\n",
       "      <td>dev_pid_1293</td>\n",
       "      <td>A plea for help : The title is true. I need he...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5821</td>\n",
       "      <td>train_pid_5822</td>\n",
       "      <td>When being rational is more dangerous : [removed]</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134</td>\n",
       "      <td>dev_pid_1135</td>\n",
       "      <td>Does it get any easier!? : Just looking to hea...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1575</td>\n",
       "      <td>train_pid_1576</td>\n",
       "      <td>I feel like gravity applies to me tenfold : Im...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5288</td>\n",
       "      <td>train_pid_5289</td>\n",
       "      <td>Anyone else not get invited anywhere for New Y...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11636</th>\n",
       "      <td>2428</td>\n",
       "      <td>dev_pid_2429</td>\n",
       "      <td>Not Sure If I Have Depression and Need Some He...</td>\n",
       "      <td>not depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>597</td>\n",
       "      <td>dev_pid_598</td>\n",
       "      <td>As my depression gets worse I feel more and mo...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>3773</td>\n",
       "      <td>train_pid_3774</td>\n",
       "      <td>27M all my friends, peers are moving with thei...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11639</th>\n",
       "      <td>1606</td>\n",
       "      <td>test_pid_1607</td>\n",
       "      <td>depression and dating are ruining my life : So...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11640</th>\n",
       "      <td>1796</td>\n",
       "      <td>dev_pid_1797</td>\n",
       "      <td>I keep losing interest. : I love drawing as yo...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11641 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             PID  \\\n",
       "0            1292    dev_pid_1293   \n",
       "1            5821  train_pid_5822   \n",
       "2            1134    dev_pid_1135   \n",
       "3            1575  train_pid_1576   \n",
       "4            5288  train_pid_5289   \n",
       "...           ...             ...   \n",
       "11636        2428    dev_pid_2429   \n",
       "11637         597     dev_pid_598   \n",
       "11638        3773  train_pid_3774   \n",
       "11639        1606   test_pid_1607   \n",
       "11640        1796    dev_pid_1797   \n",
       "\n",
       "                                                    text           label  \n",
       "0      A plea for help : The title is true. I need he...        moderate  \n",
       "1      When being rational is more dangerous : [removed]        moderate  \n",
       "2      Does it get any easier!? : Just looking to hea...        moderate  \n",
       "3      I feel like gravity applies to me tenfold : Im...        moderate  \n",
       "4      Anyone else not get invited anywhere for New Y...        moderate  \n",
       "...                                                  ...             ...  \n",
       "11636  Not Sure If I Have Depression and Need Some He...  not depression  \n",
       "11637  As my depression gets worse I feel more and mo...        moderate  \n",
       "11638  27M all my friends, peers are moving with thei...        moderate  \n",
       "11639  depression and dating are ruining my life : So...        moderate  \n",
       "11640  I keep losing interest. : I love drawing as yo...        moderate  \n",
       "\n",
       "[11641 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e9eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: {'not depression': 0, 'moderate': 1, 'severe': 1}.get(x))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: {'not depression': 0, 'moderate': 1, 'severe': 1}.get(x))\n",
    "dev_df['label'] = dev_df['label'].apply(lambda x: {'not depression': 0, 'moderate': 1, 'severe': 1}.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a267f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292</td>\n",
       "      <td>dev_pid_1293</td>\n",
       "      <td>A plea for help : The title is true. I need he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5821</td>\n",
       "      <td>train_pid_5822</td>\n",
       "      <td>When being rational is more dangerous : [removed]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134</td>\n",
       "      <td>dev_pid_1135</td>\n",
       "      <td>Does it get any easier!? : Just looking to hea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1575</td>\n",
       "      <td>train_pid_1576</td>\n",
       "      <td>I feel like gravity applies to me tenfold : Im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5288</td>\n",
       "      <td>train_pid_5289</td>\n",
       "      <td>Anyone else not get invited anywhere for New Y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11636</th>\n",
       "      <td>2428</td>\n",
       "      <td>dev_pid_2429</td>\n",
       "      <td>Not Sure If I Have Depression and Need Some He...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>597</td>\n",
       "      <td>dev_pid_598</td>\n",
       "      <td>As my depression gets worse I feel more and mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11638</th>\n",
       "      <td>3773</td>\n",
       "      <td>train_pid_3774</td>\n",
       "      <td>27M all my friends, peers are moving with thei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11639</th>\n",
       "      <td>1606</td>\n",
       "      <td>test_pid_1607</td>\n",
       "      <td>depression and dating are ruining my life : So...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11640</th>\n",
       "      <td>1796</td>\n",
       "      <td>dev_pid_1797</td>\n",
       "      <td>I keep losing interest. : I love drawing as yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11641 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             PID  \\\n",
       "0            1292    dev_pid_1293   \n",
       "1            5821  train_pid_5822   \n",
       "2            1134    dev_pid_1135   \n",
       "3            1575  train_pid_1576   \n",
       "4            5288  train_pid_5289   \n",
       "...           ...             ...   \n",
       "11636        2428    dev_pid_2429   \n",
       "11637         597     dev_pid_598   \n",
       "11638        3773  train_pid_3774   \n",
       "11639        1606   test_pid_1607   \n",
       "11640        1796    dev_pid_1797   \n",
       "\n",
       "                                                    text  label  \n",
       "0      A plea for help : The title is true. I need he...      1  \n",
       "1      When being rational is more dangerous : [removed]      1  \n",
       "2      Does it get any easier!? : Just looking to hea...      1  \n",
       "3      I feel like gravity applies to me tenfold : Im...      1  \n",
       "4      Anyone else not get invited anywhere for New Y...      1  \n",
       "...                                                  ...    ...  \n",
       "11636  Not Sure If I Have Depression and Need Some He...      0  \n",
       "11637  As my depression gets worse I feel more and mo...      1  \n",
       "11638  27M all my friends, peers are moving with thei...      1  \n",
       "11639  depression and dating are ruining my life : So...      1  \n",
       "11640  I keep losing interest. : I love drawing as yo...      1  \n",
       "\n",
       "[11641 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf22fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba95f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepressionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        '''\n",
    "        Dataset for labelling sentences with depression.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.inputs = dataframe['text']\n",
    "        self.outputs = dataframe['label']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.inputs.iloc[idx]\n",
    "        label = self.outputs.iloc[idx]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=True,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "        'ids': torch.tensor(ids, dtype=torch.long),\n",
    "        'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        'targets': torch.tensor(label, dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551d2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaCNNClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"roberta-base\", num_filters=128, kernel_size=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.roberta = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.roberta.config.hidden_size  # usually 768\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=self.hidden_size,\n",
    "                                out_channels=num_filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                padding=1)  # keep same length\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)  # output shape: (B, num_filters, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc = nn.Linear(num_filters, 1)  # binary classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Encode with RoBERTa\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state  # (B, T, H)\n",
    "\n",
    "        x = last_hidden_state.permute(0, 2, 1)  # (B, H, T)\n",
    "        x = self.conv1d(x)                      # (B, num_filters, T)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)                        # (B, num_filters, 1)\n",
    "        x = x.squeeze(2)                        # (B, num_filters)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)                     # (B, 1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3134cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DepressionDataset(train_df, roberta_tokenizer, MAX_LEN)\n",
    "dev_dataset = DepressionDataset(dev_df, roberta_tokenizer, MAX_LEN)\n",
    "test_dataset = DepressionDataset(test_df, roberta_tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df94e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=VALID_BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d6ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, scheduler, device, epochs=3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels = batch['targets'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).squeeze(1)  # (B)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        train_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['ids'].to(device)\n",
    "                attention_mask = batch['mask'].to(device)\n",
    "                labels = batch['targets'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask).squeeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Val Loss: {val_loss / len(val_loader):.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd07e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Train Loss: 0.4627 | Acc: 0.7943 | F1: 0.8683\n",
      "Val Loss: 0.4074 | Acc: 0.8189 | F1: 0.8845\n",
      "\n",
      "Epoch 2/3\n",
      "Train Loss: 0.3401 | Acc: 0.8555 | F1: 0.9039\n",
      "Val Loss: 0.3950 | Acc: 0.8229 | F1: 0.8835\n",
      "\n",
      "Epoch 3/3\n",
      "Train Loss: 0.3287 | Acc: 0.8606 | F1: 0.9071\n",
      "Val Loss: 0.3950 | Acc: 0.8229 | F1: 0.8835\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "model = RobertaCNNClassifier()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer,\n",
    "                          num_warmup_steps=0,\n",
    "                          num_training_steps=len(dev_dataloader) * num_epochs)\n",
    "\n",
    "train_model(model, train_dataloader, dev_dataloader, optimizer, scheduler, device, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d17f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"roberta_cnn_depression.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89618cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "# model = RobertaCNNClassifier()  # must match original architecture\n",
    "# model.load_state_dict(torch.load(\"roberta_cnn_depression.pt\"))\n",
    "# model.to(device)\n",
    "# model.eval()  # set to inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba523bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_depression(text, model, tokenizer, max_len=256, device=device):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'  # returns PyTorch tensors directly\n",
    "    )\n",
    "\n",
    "    # Move to device\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        prob = torch.sigmoid(logits).item()  # Convert tensor to scalar\n",
    "\n",
    "    # Convert probability to binary label\n",
    "    label = 1 if prob > 0.5 else 0\n",
    "    return label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97b86944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 (probability of depression = 0.4290)\n"
     ]
    }
   ],
   "source": [
    "# text = \"I do not feel joy, happiness or fulfilment in the things I used to love.\"\n",
    "# text = \"That movie was so depressing, it made me want to crawl into bed and cry â€” but wow, what a powerful story.\"\n",
    "text = \"I didnâ€™t feel joy, happiness or fulfilment in the hobbies I used to love â€” until I found new passions that reignited my spark.\"\n",
    "\n",
    "model.eval()\n",
    "label, prob = predict_depression(text, model, roberta_tokenizer)\n",
    "\n",
    "print(f\"Prediction: {label} (probability of depression = {prob:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3001ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device=device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels = batch['targets'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).long()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d0f5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8269\n",
      "Test F1 Score : 0.8860\n"
     ]
    }
   ],
   "source": [
    "all_preds, all_labels = evaluate_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f708c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
