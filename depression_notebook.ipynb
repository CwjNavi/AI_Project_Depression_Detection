{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\Project\\Depression_detection_project\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old read csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('data/dev.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4496\n",
      "2306\n",
      "1830\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_df))\n",
    "print(len(dev_df[dev_df['label'] == 'moderate']))\n",
    "print(len(dev_df[dev_df['label'] == 'not depression']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dev_pid_1</td>\n",
       "      <td>I enjoyed today, and I still am! Tomorrows dep...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dev_pid_2</td>\n",
       "      <td>I sorta tried to kill myself : I had a total b...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dev_pid_3</td>\n",
       "      <td>Best suicide method? : I like it quick and eas...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dev_pid_4</td>\n",
       "      <td>a story : I remember the time I'd get on my 3D...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dev_pid_5</td>\n",
       "      <td>The world only cares about beautiful people : ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>4491</td>\n",
       "      <td>dev_pid_4492</td>\n",
       "      <td>Arenâ€™t we all just tired? : Iâ€™ve been depresse...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>4492</td>\n",
       "      <td>dev_pid_4493</td>\n",
       "      <td>NEED HELP COPING : I had my life pretty much f...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>4493</td>\n",
       "      <td>dev_pid_4494</td>\n",
       "      <td>Qutting Zoloft Cold Turkey : I was on 75 mg se...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>4494</td>\n",
       "      <td>dev_pid_4495</td>\n",
       "      <td>Crying : Iâ€™m coming off my antidepressants and...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>4495</td>\n",
       "      <td>dev_pid_4496</td>\n",
       "      <td>Seeking for advice on how to overcome and deal...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4496 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           PID  \\\n",
       "0              0     dev_pid_1   \n",
       "1              1     dev_pid_2   \n",
       "2              2     dev_pid_3   \n",
       "3              3     dev_pid_4   \n",
       "4              4     dev_pid_5   \n",
       "...          ...           ...   \n",
       "4491        4491  dev_pid_4492   \n",
       "4492        4492  dev_pid_4493   \n",
       "4493        4493  dev_pid_4494   \n",
       "4494        4494  dev_pid_4495   \n",
       "4495        4495  dev_pid_4496   \n",
       "\n",
       "                                                   text     label  \n",
       "0     I enjoyed today, and I still am! Tomorrows dep...  moderate  \n",
       "1     I sorta tried to kill myself : I had a total b...  moderate  \n",
       "2     Best suicide method? : I like it quick and eas...  moderate  \n",
       "3     a story : I remember the time I'd get on my 3D...  moderate  \n",
       "4     The world only cares about beautiful people : ...  moderate  \n",
       "...                                                 ...       ...  \n",
       "4491  Arenâ€™t we all just tired? : Iâ€™ve been depresse...    severe  \n",
       "4492  NEED HELP COPING : I had my life pretty much f...    severe  \n",
       "4493  Qutting Zoloft Cold Turkey : I was on 75 mg se...    severe  \n",
       "4494  Crying : Iâ€™m coming off my antidepressants and...    severe  \n",
       "4495  Seeking for advice on how to overcome and deal...    severe  \n",
       "\n",
       "[4496 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('data/train_aug.tsv', delimiter='\\t')\n",
    "# train_df = pd.read_csv('data/balanced_train.tsv', delimiter='\\t')\n",
    "train_df = pd.read_csv('./data/train.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8891\n",
      "6004\n",
      "1985\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(train_df[train_df['label'] == 'moderate']))\n",
    "print(len(train_df[train_df['label'] == 'not depression']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_pid_1</td>\n",
       "      <td>Waiting for my mind to have a breakdown once t...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_pid_2</td>\n",
       "      <td>My new years resolution : I'm gonna get my ass...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_pid_3</td>\n",
       "      <td>New year : Somone else Feeling like 2020 will ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train_pid_4</td>\n",
       "      <td>My story I guess : Hi, Im from Germany and my ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train_pid_5</td>\n",
       "      <td>Sat in the dark and cried myself going into th...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8886</th>\n",
       "      <td>8886</td>\n",
       "      <td>train_pid_8887</td>\n",
       "      <td>Ways to reverse memory loss from depression? :...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8887</th>\n",
       "      <td>8887</td>\n",
       "      <td>train_pid_8888</td>\n",
       "      <td>A Comprehensive Guide To Slowly Getting Better...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8888</th>\n",
       "      <td>8888</td>\n",
       "      <td>train_pid_8889</td>\n",
       "      <td>I donâ€™t think college is right for me : TW: su...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8889</th>\n",
       "      <td>8889</td>\n",
       "      <td>train_pid_8890</td>\n",
       "      <td>Please help: Severe insomnia affecting me in m...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8890</th>\n",
       "      <td>8890</td>\n",
       "      <td>train_pid_8891</td>\n",
       "      <td>With each passing day my depression is getting...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8891 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             PID  \\\n",
       "0              0     train_pid_1   \n",
       "1              1     train_pid_2   \n",
       "2              2     train_pid_3   \n",
       "3              3     train_pid_4   \n",
       "4              4     train_pid_5   \n",
       "...          ...             ...   \n",
       "8886        8886  train_pid_8887   \n",
       "8887        8887  train_pid_8888   \n",
       "8888        8888  train_pid_8889   \n",
       "8889        8889  train_pid_8890   \n",
       "8890        8890  train_pid_8891   \n",
       "\n",
       "                                                   text     label  \n",
       "0     Waiting for my mind to have a breakdown once t...  moderate  \n",
       "1     My new years resolution : I'm gonna get my ass...  moderate  \n",
       "2     New year : Somone else Feeling like 2020 will ...  moderate  \n",
       "3     My story I guess : Hi, Im from Germany and my ...  moderate  \n",
       "4     Sat in the dark and cried myself going into th...  moderate  \n",
       "...                                                 ...       ...  \n",
       "8886  Ways to reverse memory loss from depression? :...    severe  \n",
       "8887  A Comprehensive Guide To Slowly Getting Better...    severe  \n",
       "8888  I donâ€™t think college is right for me : TW: su...    severe  \n",
       "8889  Please help: Severe insomnia affecting me in m...    severe  \n",
       "8890  With each passing day my depression is getting...    severe  \n",
       "\n",
       "[8891 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test_pid_1</td>\n",
       "      <td>Im scared : This is it. I lie to myself every ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test_pid_2</td>\n",
       "      <td>New to this but just wanted to vent : I just f...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test_pid_3</td>\n",
       "      <td>Iâ€™m sad : Itâ€™s kinda always been an issue. I w...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test_pid_4</td>\n",
       "      <td>Lonely but not alone. : All of my immediately ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test_pid_5</td>\n",
       "      <td>This year has been trash. : I dont know why Iâ€™...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>3240</td>\n",
       "      <td>test_pid_3241</td>\n",
       "      <td>Feeling lonely. : Hi reddit, I havenâ€™t posted ...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>3241</td>\n",
       "      <td>test_pid_3242</td>\n",
       "      <td>When would suicide be right? : So I got back f...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>3242</td>\n",
       "      <td>test_pid_3243</td>\n",
       "      <td>Lowest Iâ€™ve ever been ever. : To make a long s...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>3243</td>\n",
       "      <td>test_pid_3244</td>\n",
       "      <td>Does the Toxoplasma Gondii ruined my life ? (f...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>3244</td>\n",
       "      <td>test_pid_3245</td>\n",
       "      <td>Getting the correct diagnosis : Currently goin...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3245 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0            PID  \\\n",
       "0              0     test_pid_1   \n",
       "1              1     test_pid_2   \n",
       "2              2     test_pid_3   \n",
       "3              3     test_pid_4   \n",
       "4              4     test_pid_5   \n",
       "...          ...            ...   \n",
       "3240        3240  test_pid_3241   \n",
       "3241        3241  test_pid_3242   \n",
       "3242        3242  test_pid_3243   \n",
       "3243        3243  test_pid_3244   \n",
       "3244        3244  test_pid_3245   \n",
       "\n",
       "                                                   text     label  \n",
       "0     Im scared : This is it. I lie to myself every ...  moderate  \n",
       "1     New to this but just wanted to vent : I just f...  moderate  \n",
       "2     Iâ€™m sad : Itâ€™s kinda always been an issue. I w...  moderate  \n",
       "3     Lonely but not alone. : All of my immediately ...  moderate  \n",
       "4     This year has been trash. : I dont know why Iâ€™...  moderate  \n",
       "...                                                 ...       ...  \n",
       "3240  Feeling lonely. : Hi reddit, I havenâ€™t posted ...    severe  \n",
       "3241  When would suicide be right? : So I got back f...    severe  \n",
       "3242  Lowest Iâ€™ve ever been ever. : To make a long s...    severe  \n",
       "3243  Does the Toxoplasma Gondii ruined my life ? (f...    severe  \n",
       "3244  Getting the correct diagnosis : Currently goin...    severe  \n",
       "\n",
       "[3245 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/reshuffle_train.tsv\", delimiter='\\t')\n",
    "dev_df = pd.read_csv(\"./data/reshuffle_dev.tsv\", delimiter='\\t')\n",
    "test_df = pd.read_csv(\"./data/reshuffle_test.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the datasets\n",
    "\n",
    "Firstly, we have to convert the labels from not depression, moderate, severe to 0, 1, 2\n",
    "\n",
    "Then we have to tokenize and truncate the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "rob_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "max_len = 512\n",
    "\n",
    "def process_labels(example):\n",
    "    new_label = {'not depression': 0, 'moderate': 1, 'severe': 2}.get(example['label'], example['label'])\n",
    "    return {'label': new_label}\n",
    "    \n",
    "def process_text(example, tokenizer=rob_tokenizer, max_len=512, padding='max_length', truncation=True):\n",
    "    return tokenizer(example['text'], max_length=max_len, padding=padding, truncation=truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11641/11641 [00:00<00:00, 18261.10 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11641/11641 [00:02<00:00, 5389.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2495/2495 [00:00<00:00, 17719.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2495/2495 [00:00<00:00, 5459.05 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2496/2496 [00:00<00:00, 17959.34 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2496/2496 [00:00<00:00, 5556.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(process_labels)\n",
    "train_dataset = train_dataset.map(process_text, batched=True)\n",
    "\n",
    "test_dataset = test_dataset.map(process_labels)\n",
    "test_dataset = test_dataset.map(process_text, batched=True)\n",
    "\n",
    "dev_dataset = dev_dataset.map(process_labels)\n",
    "dev_dataset = dev_dataset.map(process_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using AdamW\n",
    "\n",
    "different LR\n",
    "\n",
    "different dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for calculating weights for weighted binary prediction\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# Example: assuming train_dataset has a 'label' field\n",
    "labels = [example['label'] for example in train_dataset]\n",
    "class_counts = Counter(labels)\n",
    "\n",
    "# Compute positive class weight for BCEWithLogitsLoss\n",
    "# pos_weight = # of non-depression / # of depression\n",
    "pos_weight = torch.tensor([class_counts[0] / class_counts[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, pos_weight, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Compute weighted loss\n",
    "        loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight.to(logits.device))\n",
    "        loss = loss_fct(logits.view(-1), labels.float().view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 3 ## 0 or 1 for no depression and depression\n",
    "MODEL_LABEL = \"labels3_reshuffled_trainDevTest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_score = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1_score.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{MODEL_LABEL}\",\n",
    "    evaluation_strategy=\"epoch\",  # evaluates on dev after each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True, # <- Load best model based on F1\n",
    "    metric_for_best_model=\"f1\", # <- Use F1 as selection metric\n",
    "    greater_is_better=True, # <- Higher F1 is better\n",
    "    fp16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_32268\\714501680.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    "    # pos_weight=pos_weight # for weighted loss trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11648' max='11648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11648/11648 47:15, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.672900</td>\n",
       "      <td>0.641393</td>\n",
       "      <td>0.739984</td>\n",
       "      <td>0.643283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.503900</td>\n",
       "      <td>0.570789</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.701639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.781346</td>\n",
       "      <td>0.765224</td>\n",
       "      <td>0.706025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.937771</td>\n",
       "      <td>0.772436</td>\n",
       "      <td>0.716803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>1.253358</td>\n",
       "      <td>0.776843</td>\n",
       "      <td>0.729033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>1.427183</td>\n",
       "      <td>0.772837</td>\n",
       "      <td>0.717857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>1.577010</td>\n",
       "      <td>0.768429</td>\n",
       "      <td>0.714701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>1.716262</td>\n",
       "      <td>0.772035</td>\n",
       "      <td>0.718817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_log = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for Binary_Classificationlr_2e-05_wd_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.830032</td>\n",
       "      <td>0.686610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>1.393730</td>\n",
       "      <td>0.652135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>1.055826</td>\n",
       "      <td>0.645685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>1.554594</td>\n",
       "      <td>0.670151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.054934</td>\n",
       "      <td>0.681495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>2.009965</td>\n",
       "      <td>0.671041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.401954</td>\n",
       "      <td>0.678381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>2.429269</td>\n",
       "      <td>0.676157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.544962</td>\n",
       "      <td>0.685943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>2.586025</td>\n",
       "      <td>0.684609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_2e-05_wd_0.01 - Accuracy: 0.6866103202846975\n",
      "\n",
      "Starting training for Binary_Classificationlr_2e-05_wd_0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>0.700400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>1.317111</td>\n",
       "      <td>0.665480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>1.513499</td>\n",
       "      <td>0.657251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>1.720487</td>\n",
       "      <td>0.673043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>1.963503</td>\n",
       "      <td>0.675712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>2.321710</td>\n",
       "      <td>0.671263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.333368</td>\n",
       "      <td>0.673265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>2.488573</td>\n",
       "      <td>0.679270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.611288</td>\n",
       "      <td>0.683052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>2.668933</td>\n",
       "      <td>0.673932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_2e-05_wd_0.02 - Accuracy: 0.7004003558718861\n",
      "\n",
      "Starting training for Binary_Classificationlr_5e-05_wd_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.676800</td>\n",
       "      <td>0.778881</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.537700</td>\n",
       "      <td>0.701852</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.742900</td>\n",
       "      <td>0.737447</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.676860</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.713198</td>\n",
       "      <td>0.407028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.677182</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>0.761924</td>\n",
       "      <td>0.407028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>0.407028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.548800</td>\n",
       "      <td>0.737083</td>\n",
       "      <td>0.407028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_5e-05_wd_0.01 - Accuracy: 0.5929715302491103\n",
      "\n",
      "Starting training for Binary_Classificationlr_5e-05_wd_0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566700</td>\n",
       "      <td>0.818744</td>\n",
       "      <td>0.667482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>1.086672</td>\n",
       "      <td>0.654137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>1.081498</td>\n",
       "      <td>0.664146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>1.217484</td>\n",
       "      <td>0.673710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>1.248024</td>\n",
       "      <td>0.688390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>1.274273</td>\n",
       "      <td>0.682384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>1.509742</td>\n",
       "      <td>0.672153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.139800</td>\n",
       "      <td>1.553740</td>\n",
       "      <td>0.675489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>1.763238</td>\n",
       "      <td>0.673932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>1.842898</td>\n",
       "      <td>0.667037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_5e-05_wd_0.02 - Accuracy: 0.6883896797153025\n",
      "\n",
      "Starting training for Binary_Classificationlr_0.0001_wd_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.784447</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.837740</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>0.755501</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>0.785863</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.505900</td>\n",
       "      <td>0.785339</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.782325</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.822187</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.604600</td>\n",
       "      <td>0.781387</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.774961</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.538500</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_0.0001_wd_0.01 - Accuracy: 0.5929715302491103\n",
      "\n",
      "Starting training for Binary_Classificationlr_0.0001_wd_0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.670200</td>\n",
       "      <td>0.785380</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.839946</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>0.755866</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.787447</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.785113</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.541400</td>\n",
       "      <td>0.782985</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.472500</td>\n",
       "      <td>0.821428</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.781386</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.547300</td>\n",
       "      <td>0.775454</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.545500</td>\n",
       "      <td>0.793746</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_0.0001_wd_0.02 - Accuracy: 0.5929715302491103\n",
      "\n",
      "Starting training for Binary_Classificationlr_0.0003_wd_0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 48:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.768319</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.753376</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472200</td>\n",
       "      <td>0.794095</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.768490</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.835490</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.756986</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.548400</td>\n",
       "      <td>0.760233</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.534200</td>\n",
       "      <td>0.766180</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='562' max='562' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [562/562 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Binary_Classificationlr_0.0003_wd_0.01 - Accuracy: 0.5929715302491103\n",
      "\n",
      "Starting training for Binary_Classificationlr_0.0003_wd_0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_20692\\3965535182.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3412' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3412/11120 14:46 < 33:22, 3.85 it/s, Epoch 3.07/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>0.772036</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.566600</td>\n",
       "      <td>0.851762</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.734500</td>\n",
       "      <td>0.754242</td>\n",
       "      <td>0.592972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     39\u001b[39m training_args = TrainingArguments(\n\u001b[32m     40\u001b[39m     output_dir=output_dir,\n\u001b[32m     41\u001b[39m     evaluation_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m     fp16=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m trainer = Trainer(\n\u001b[32m     57\u001b[39m     model=model,\n\u001b[32m     58\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m     63\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Save final model and metrics\u001b[39;00m\n\u001b[32m     68\u001b[39m trainer.save_model(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/final_model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\trainer.py:2241\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2239\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\HW\\env\\Lib\\site-packages\\transformers\\trainer.py:2553\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2548\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "NUM_LABELS = 2\n",
    "MODEL_TYPE = 'Binary_Classification'\n",
    "\n",
    "# Assuming tokenizer, train_dataset, dev_dataset are already defined and preprocessed\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Hyperparameter options\n",
    "LRs = [2e-5, 5e-5, 1e-4, 3e-4]\n",
    "weight_decays = [0.01, 0.02]\n",
    "\n",
    "# Loop through all combinations\n",
    "for lr in LRs:\n",
    "    for wd in weight_decays:\n",
    "        run_name = f\"{MODEL_TYPE}lr_{lr}_wd_{wd}\"\n",
    "        output_dir = f\"./results/{run_name}\"\n",
    "\n",
    "        print(f\"\\nStarting training for {run_name}\")\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=NUM_LABELS)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=10,\n",
    "            weight_decay=wd,\n",
    "            logging_dir=f\"./logs/{run_name}\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            logging_steps=10,\n",
    "            save_total_limit=1,  # only keep best checkpoint\n",
    "            fp16=True\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=dev_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Save final model and metrics\n",
    "        trainer.save_model(f\"{output_dir}/final_model\")\n",
    "        metrics = trainer.evaluate()\n",
    "        with open(f\"{output_dir}/metrics.txt\", \"w\") as f:\n",
    "            for key, val in metrics.items():\n",
    "                f.write(f\"{key}: {val}\\n\")\n",
    "\n",
    "        print(f\"Finished {run_name} - Accuracy: {metrics.get('eval_accuracy', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
