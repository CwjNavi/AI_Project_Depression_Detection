{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6995927",
   "metadata": {},
   "source": [
    "This notebook uses the simpler dataset\n",
    "https://www.kaggle.com/datasets/infamouscoder/depression-reddit-cleaned/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3af6301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\Project\\Depression_detection_project\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4458aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"./data/depression_dataset_reddit_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9f07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>is that snow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>moulin rouge mad me cry once again</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728</th>\n",
       "      <td>trying to shout but can t find people on the list</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>ughh can t find my red sox hat got ta wear thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730</th>\n",
       "      <td>slept wonderfully finally tried swatching for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7731 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  is_depression\n",
       "0     we understand that most people who reply immed...              1\n",
       "1     welcome to r depression s check in post a plac...              1\n",
       "2     anyone else instead of sleeping more when depr...              1\n",
       "3     i ve kind of stuffed around a lot in my life d...              1\n",
       "4     sleep is my greatest and most comforting escap...              1\n",
       "...                                                 ...            ...\n",
       "7726                                       is that snow              0\n",
       "7727                 moulin rouge mad me cry once again              0\n",
       "7728  trying to shout but can t find people on the list              0\n",
       "7729  ughh can t find my red sox hat got ta wear thi...              0\n",
       "7730  slept wonderfully finally tried swatching for ...              0\n",
       "\n",
       "[7731 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25ac4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp, test_df = train_test_split(raw_df, test_size=0.15, stratify=raw_df['is_depression'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3a56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train_temp, test_size=0.17, stratify=train_temp['is_depression'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a64b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>my alt acc look like it s made by someone with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7215</th>\n",
       "      <td>why do most video i play skip and jump</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>missing the fab five</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>i just got another thing i have to look out an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>didnt announce reading lineup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>amsterdamant unfortunately i didn t dream abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>i just took the pill i don t know how many it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>another set of ipod earbuds dying left going q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>kristenkreuk fiuhh nice to get info from you i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>i m about to be living in nyc and have never d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5453 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_text  is_depression\n",
       "3677  my alt acc look like it s made by someone with...              1\n",
       "7215             why do most video i play skip and jump              0\n",
       "5741                               missing the fab five              0\n",
       "384   i just got another thing i have to look out an...              1\n",
       "6448                      didnt announce reading lineup              0\n",
       "...                                                 ...            ...\n",
       "6138  amsterdamant unfortunately i didn t dream abou...              0\n",
       "2048  i just took the pill i don t know how many it ...              1\n",
       "7661  another set of ipod earbuds dying left going q...              0\n",
       "6591  kristenkreuk fiuhh nice to get info from you i...              0\n",
       "2492  i m about to be living in nyc and have never d...              1\n",
       "\n",
       "[5453 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7cde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={'clean_text': 'text', 'is_depression': 'label'})\n",
    "validation_df = validation_df.rename(columns={'clean_text': 'text', 'is_depression': 'label'})\n",
    "test_df = test_df.rename(columns={'clean_text': 'text', 'is_depression': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34538ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'roberta-base'\n",
    "rob_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "max_len = 512\n",
    "\n",
    "def process_labels(example):\n",
    "    new_label = {'not depression': 0, 'depression': 1}.get(example['label'], example['label'])\n",
    "    return {'label': new_label}\n",
    "    \n",
    "def process_text(example, tokenizer=rob_tokenizer, max_len=512, padding='max_length', truncation=True):\n",
    "    return tokenizer(example['text'], max_length=max_len, padding=padding, truncation=truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b9bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c246646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5453/5453 [00:00<00:00, 13647.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5453/5453 [00:00<00:00, 6189.10 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1160/1160 [00:00<00:00, 20594.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1160/1160 [00:00<00:00, 6664.25 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1118/1118 [00:00<00:00, 21902.78 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1118/1118 [00:00<00:00, 6482.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(process_labels)\n",
    "train_dataset = train_dataset.map(process_text, batched=True)\n",
    "\n",
    "test_dataset = test_dataset.map(process_labels)\n",
    "test_dataset = test_dataset.map(process_text, batched=True)\n",
    "\n",
    "validation_dataset = validation_dataset.map(process_labels)\n",
    "validation_dataset = validation_dataset.map(process_text, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebff5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 2 ## 0 or 1 for no depression and depression\n",
    "MODEL_LABEL = \"infamous_coder\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72fc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_score = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1_score.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb599b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ivanc\\OneDrive - Singapore University of Technology and Design\\School Work\\Term_8\\AI\\Project\\Depression_detection_project\\env\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{MODEL_LABEL}\",\n",
    "    evaluation_strategy=\"epoch\",  # evaluates on dev after each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True, # <- Load best model based on F1\n",
    "    metric_for_best_model=\"f1\", # <- Use F1 as selection metric\n",
    "    greater_is_better=True, # <- Higher F1 is better\n",
    "    fp16=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f3f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivanc\\AppData\\Local\\Temp\\ipykernel_24476\\3640888429.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    "    # pos_weight=pos_weight # for weighted loss trainer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49482c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5456' max='5456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5456/5456 22:30, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.080483</td>\n",
       "      <td>0.979428</td>\n",
       "      <td>0.979423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>0.971377</td>\n",
       "      <td>0.971376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.107390</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>0.981216</td>\n",
       "      <td>0.981216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.981216</td>\n",
       "      <td>0.981213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.137387</td>\n",
       "      <td>0.981216</td>\n",
       "      <td>0.981213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.153274</td>\n",
       "      <td>0.979428</td>\n",
       "      <td>0.979425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.154373</td>\n",
       "      <td>0.980322</td>\n",
       "      <td>0.980319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_log = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f24eee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47f1c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc6cb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b09e4445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1 (Depressed)\n",
      "Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "text = \"I am quite happy right now.\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "# Get model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = torch.argmax(probs, dim=1).item()\n",
    "confidence = probs[0][predicted_class].item()\n",
    "\n",
    "# Output result\n",
    "print(f\"Predicted Class: {predicted_class} ({'Depressed' if predicted_class == 1 else 'Not Depressed'})\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6808282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
